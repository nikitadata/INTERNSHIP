{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import selenium\nimport pandas as pd\nfrom selenium import webdriver\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "driver = webdriver.Chrome()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "driver.get(\"https://www.amazon.in/\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "user_input = input(\"Press ENTER after product name: \")       #press enter after typing product name",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "input_field = driver.find_element(By.ID, \"twotabsearchtextbox\")\ninput_field.send_keys(user_input)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "press=driver.find_element(By.XPATH, \"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\npress.click()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#2\nName9=[]\nName_of_productf=[]    \nPrice9=[]\nReturn_exchangee=[]\nExpected_deliverym=[]\nAvailabilityl=[]\nProduct_urlf=[]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "start = 0            #name\nend = 3\nfor page in range(start,end):\n    named=driver.find_elements(By.XPATH, '//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-4\"]')\n    for i in named:\n        title=user_input\n        Name9.append(title)\nnext_button = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div[1]/div/span[1]/div[1]/div[67]/div/div/span/a[3]')\nnext_button.click()\ndriver.back()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "start = 0                 #name of product\nend = 3\nfor page in range(start,end):\n    names=driver.find_elements(By.XPATH, '//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-4\"]')\n    for i in names:\n        title=i.text\n        Name_of_productf.append(title)\nnext_button = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div[1]/div/span[1]/div[1]/div[67]/div/div/span/a[3]')\nnext_button.click()\ndriver.back()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "start = 0                 #price\nend = 3\nfor page in range(start,end):\n    prize6=driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n    Prizes6 = prize6\n    for i in Prizes6:\n        title=i.text\n        Price9.append(title)\nnext_button = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div[1]/div/span[1]/div[1]/div[67]/div/div/span/a[3]')\nnext_button.click()\ndriver.back()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "len(Price9)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "default_policy = ('-')\n\nstart = 0            #return exchange\nend = 3\nfor page in range(start,end):\n    nums=driver.find_elements(By.XPATH, '//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-4\"]')\n    for i in nums:\n        title=default_policy\n        Return_exchangee.append(title)\nnext_button = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div[1]/div/span[1]/div[1]/div[67]/div/div/span/a[3]')\nnext_button.click()\ndriver.back()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "len(Return_exchangee)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Availability =('-')\n\nstart = 0                 #availability  \nend = 3\nfor page in range(start,end):\n    wezl=driver.find_elements(By.XPATH, '//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-4\"]')\n    for i in wezl:\n        title=Availability\n        Availabilityl.append(title)\nnext_button = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div[1]/div/span[1]/div[1]/div[67]/div/div/span/a[3]')\nnext_button.click()\ndriver.back()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "len(Availabilityl)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "start = 0                 #url\nend = 3\nfor page in range(start,end):\n    RAY=driver.find_elements(By.XPATH, '//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n    for i in RAY:\n        f = i.get_attribute('href')\n        n = f[:180]\n    \nnext_button = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div[1]/div/span[1]/div[1]/div[67]/div/div/span/a[3]')\nnext_button.click()\ndriver.back()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "a_data=pd.DataFrame({})\na_data['Name']=Name9[:180]\na_data['Name_of_product']=Name_of_productf[:180]\na_data['Price']=Price9[:180]\na_data['Return_exchange']=Return_exchangee[:180]\na_data['Expected_delivery']=Expected_deliverym[:180]\na_data['Availability']=Availabilityl[:180]\na_data['Product_url']=n[:180]\na_data",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#3\npip install selenium\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\ndriver_path = 'path_to_chromedriver'\n\ndriver = webdriver.Chrome(driver_path)\n\ndriver.get('https://images.google.com')\n\nsearch_bar = driver.find_element(By.NAME, 'q')\nkeywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n\nfor keyword in keywords:\n  search_bar.clear()\n  search_bar.send_keys(keyword)\n  search_bar.send_keys(Keys.RETURN)\n\n\n  WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'rg_i')))\n\n\n  image_elements = driver.find_elements(By.CLASS_NAME, 'rg_i')\n  image_urls = [element.get_attribute('src') for element in image_elements]\n\n  \n  print(f\"Top 10 images for '{keyword}':\")\n  for url in image_urls[:10]:\n   print(url)\n      \ndriver.quit()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'SyntaxError'>",
          "evalue": "invalid syntax (<ipython-input-4-4be1d5847f5e>, line 1)",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install selenium\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "#4\npip install beautifulsoup4\npip install pandas\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\n\ndef scrape_smartphones():\n  url = \"https://www.flipkart.com/search?q=smartphone\"  # Replace \"smartphone\" with your desired search query\n  response = requests.get(url)\n  soup = BeautifulSoup(response.content, 'html.parser')\n  \n  smartphones = []\n  \n  results = soup.find_all('div', {'class': '_1AtVbE'})\n  \n  for result in results:\n  details = {}\n  \n\n  details['Brand Name'] = result.find('div', {'class': '_4rR01T'}).text\n  details['Smartphone Name'] = result.find('a', {'class': 'IRpwTa'}).text\n  details['Colour'] = result.find('div', {'class': '_2WkVRV'}).text\n  details['RAM'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[0].text\n  details['Storage(ROM)'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[1].text\n  details['Primary Camera'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[2].text\n  details['Secondary Camera'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[3].text\n  details['Display Size'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[4].text\n  details['Battery Capacity'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[5].text\n  details['Price'] = result.find('div', {'class': '_30jeq3 _1_WHN1'}).text\n  details['Product URL'] = \"https://www.flipkart.com\" + result.find('a', {'class': 'IRpwTa'})['href']\n  \n  smartphones.append(details)\n  \n  return smartphones\n\n\nsmartphones = scrape_smartphones()\n\n\ndf = pd.DataFrame(smartphones)\n\n\ndf.fillna(\"-\", inplace=True)\n\n\ndf.to_csv('smartphones.csv', index=False)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#5\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_coordinates(city):\n  formatted_city = city.replace(\" \", \"+\")\n\n  url = f\"https://www.google.com/maps/search/{formatted_city}\"\n  response = requests.get(url)\n\n  \n  soup = BeautifulSoup(response.text, \"html.parser\")\n\n \n  coordinates_element = soup.find(\"meta\", itemprop=\"image\")\n\n  \n  coordinates = coordinates_element[\"content\"].split(\";\")[1].strip().split(\",\")\n\n  \n  return float(coordinates[0]), float(coordinates[1])\n\n\ncity = input(\"Enter a city name: \")\nlatitude, longitude = get_coordinates(city)\nprint(f\"The coordinates of {city} are: Latitude: {latitude}, Longitude: {longitude}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#6\nfrom selenium import webdriver\nimport time\n\n\ndriver = webdriver.Chrome('path_to_chromedriver')\n\n\ndriver.get('https://www.digit.in/')\n\n\nsearch_bar = driver.find_element_by_id('searchDiv')\nsearch_bar.send_keys('gaming laptops')\nsearch_bar.submit()\n\n\ntime.sleep(2)\n\n\nlaptop_elements = driver.find_elements_by_class_name('searchPage')\nlaptop_details = []\n\nfor laptop in laptop_elements:\n  name = laptop.find_element_by_class_name('searchProductTitle').text\n  price = laptop.find_element_by_class_name('searchPrice').text\n  specifications = laptop.find_element_by_class_name('searchSpec').text\n  \n  laptop_details.append({\n  'Name': name,\n  'Price': price,\n  'Specifications': specifications\n  })\n\n\nfor laptop in laptop_details:\n  print(laptop)\n\n\ndriver.quit()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#7\nimport requests\nfrom bs4 import BeautifulSoup\n\n\nurl = \"https://www.forbes.com/billionaires/\"\nresponse = requests.get(url)\n\n\nsoup = BeautifulSoup(response.content, \"html.parser\")\n\n\ntable = soup.find(\"table\", class_=\"table\")\n\n\nrows = table.find_all(\"tr\")\n\n\nfor row in rows:\n    columns = row.find_all(\"td\")\n  \n  \n  rank = columns[0].text.strip()\n  name = columns[1].text.strip()\n  net_worth = columns[2].text.strip()\n  age = columns[3].text.strip()\n  citizenship = columns[4].text.strip()\n  source = columns[5].text.strip()\n  industry = columns[6].text.strip()\n  \n \n  print(\"Rank:\", rank)\n  print(\"Name:\", name)\n  print(\"Net Worth:\", net_worth)\n  print(\"Age:\", age)\n  print(\"Citizenship:\", citizenship)\n  print(\"Source:\", source)\n  print(\"Industry:\", industry)\n  print()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#8\nfrom selenium import webdriver\nimport time\n\n\ndriver = webdriver.Chrome('path_to_chromedriver')  \n\nvideo_url = 'https://www.youtube.com/watch?v=your_video_id' \ndriver.get(video_url)\n\n\nscroll_pause_time = 2  \nscrolls = 10  \n\nfor _ in range(scrolls):\n  driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n  time.sleep(scroll_pause_time)\n\n\ncomments = driver.find_elements_by_xpath('//yt-formatted-string[@id=\"content-text\"]')\nupvotes = driver.find_elements_by_xpath('//span[@id=\"vote-count-middle\"]')\ntimes = driver.find_elements_by_xpath('//a[@class=\"yt-simple-endpoint style-scope yt-formatted-string\"]')\n\n\nextracted_data = []\nfor comment, upvote, time in zip(comments, upvotes, times):\n  extracted_data.append({\n  'comment': comment.text,\n  'upvote': upvote.text,\n  'time': time.text\n  })\n\n\ndriver.quit()\n\n\nfor data in extracted_data:\n  print(data)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#9\nimport requests\nfrom bs4 import BeautifulSoup\n\n\nurl = \"https://www.hostelworld.com/hostels/London\"\nresponse = requests.get(url)\n\n\nsoup = BeautifulSoup(response.content, \"html.parser\")\n\n# Find all the hostel containers\nhostels = soup.find_all(\"div\", class_=\"fabresult\")\n\n# Iterate over each hostel container and extract the required information\nfor hostel in hostels:\n  # Extract hostel name\n  name = hostel.find(\"h2\", class_=\"fabresult-title\").text.strip()\n  \n  # Extract distance from city centre\n  distance = hostel.find(\"span\", class_=\"distance\").text.strip()\n  \n  # Extract ratings\n  ratings = hostel.find(\"div\", class_=\"rating\").text.strip()\n  \n  # Extract total reviews\n  total_reviews = hostel.find(\"div\", class_=\"reviews\").text.strip()\n  \n  # Extract overall reviews\n  overall_reviews = hostel.find(\"div\", class_=\"overall\").text.strip()\n  \n  # Extract privates from price\n  privates_price = hostel.find(\"div\", class_=\"price-col\").find(\"div\", class_=\"price\").text.strip()\n  \n  # Extract dorms from price\n  dorms_price = hostel.find(\"div\", class_=\"price-col\").find(\"div\", class_=\"price\").find_next_sibling(\"div\", class_=\"price\").text.strip()\n  \n  # Extract facilities\n  facilities = hostel.find(\"div\", class_=\"facilities\").text.strip()\n  \n  # Extract property description\n  description = hostel.find(\"div\", class_=\"description\").text.strip()\n  \n  # Print the extracted information\n  print(\"Hostel Name:\", name)\n  print(\"Distance from City Centre:\", distance)\n  print(\"Ratings:\", ratings)\n  print(\"Total Reviews:\", total_reviews)\n  print(\"Overall Reviews:\", overall_reviews)\n  print(\"Privates from Price:\", privates_price)\n  print(\"Dorms from Price:\", dorms_price)\n  print(\"Facilities:\", facilities)\n  print(\"Property Description:\", description)\n  print()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}